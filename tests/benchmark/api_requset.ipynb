{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "swparse_api_key = os.environ[\"SWPARSE_KEY\"]\n",
    "BASE_URL =  os.environ[\"BASE_URL\"]\n",
    "\n",
    "\n",
    "def get_file_content(filename: str)-> bytes:\n",
    "   \n",
    "    with open(f\"pdf/{filename}\", mode=\"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_file(filepath: str, content:str):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "\n",
    "def upload_file(files: dict[str, tuple[str, bytes, str]], force_ocr: bool = False, plain_text: bool = False)-> str:    \n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"force_ocr\": force_ocr,\n",
    "        \"plain_text\": plain_text\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {swparse_api_key}'\n",
    "    }\n",
    "    try:\n",
    "        \n",
    "        response = requests.post(f\"{BASE_URL}/api/parsing/upload\", files=files, headers=headers, data = data)\n",
    "        if response.status_code == 201:\n",
    "            print(\"File uploaded successfully!\")\n",
    "            res  = response.json()\n",
    "            print(res)\n",
    "\n",
    "            return res[\"id\"]\n",
    "     \n",
    "        else:\n",
    "            print(f\"Failed to upload the file. Status code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def get_result(job_id: str,  result_type:str) -> str:        \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {swparse_api_key}'\n",
    "    }\n",
    "    while True:\n",
    "  \n",
    "        response = requests.get(f\"{BASE_URL}/api/parsing/job/{job_id}/result/{result_type}\", headers=headers)\n",
    "         \n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "\n",
    "        time.sleep(.5)\n",
    " \n",
    "    result = response.json()\n",
    "    output = result[result_type]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "\n",
    "def process_file(files: dict[str, tuple[str, bytes, str]], result_type: str, attempts:int = 5, force_ocr:bool=False, plain_text:bool=False)->list[object]:\n",
    "        times =  []\n",
    "        filename, _, _ = list( files.values())[0]\n",
    "        for attempt in range(attempts):\n",
    "                start_time = datetime.now()\n",
    "                \n",
    "                job_id = upload_file(files, force_ocr=force_ocr, plain_text=plain_text)\n",
    "                print(f\"Attmpet {attempt}\")\n",
    "                result = get_result(job_id, result_type=result_type)\n",
    "                end_time = datetime.now()                     \n",
    "                \n",
    "                time_taken = end_time - start_time   \n",
    "                times.append(time_taken)\n",
    "        filename = filename.replace(\".pdf\", \"\")\n",
    "        if force_ocr:\n",
    "            filename = f\"{filename}(force_ocr)\" \n",
    "        if plain_text:\n",
    "                filename = f\"{filename}(plain_text).txt\"\n",
    "        else:\n",
    "            filename = f\"{filename}.md\"\n",
    "        write_file(f\"output/{filename}\", result)\n",
    "                \n",
    "        return times \n",
    " \n",
    " \n",
    "def get_average_str(times:list[object]):\n",
    "    total_time = sum(times, timedelta())\n",
    "    avg_time = total_time / len(times)\n",
    "    return get_time_str(avg_time)\n",
    "\n",
    "\n",
    "def get_time_str(time:object)->str:\n",
    "    minutes, seconds = divmod(time.seconds, 60)\n",
    "    milliseconds = time.microseconds // 1000\n",
    "    \n",
    "    return f\"Time Taken: {minutes} min {seconds} sec {milliseconds} ms\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:2f8106f8-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/5d6faf070bfa5d230b34da0bf9c0be79.pdf'}\n",
      "Attmpet 0\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:4eae24fc-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/5d6faf070bfa5d230b34da0bf9c0be79.pdf'}\n",
      "Attmpet 1\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:736d2ba8-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/5d6faf070bfa5d230b34da0bf9c0be79.pdf'}\n",
      "Attmpet 2\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:93abd540-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/5d6faf070bfa5d230b34da0bf9c0be79.pdf'}\n",
      "Attmpet 3\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:b643a0ec-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/5d6faf070bfa5d230b34da0bf9c0be79.pdf'}\n",
      "Attmpet 4\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:d8f9dcb4-d56b-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/2340cd88df33ff3c70188c3cbd2a9476.pdf'}\n",
      "Attmpet 0\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:6e2dad42-d56c-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/2340cd88df33ff3c70188c3cbd2a9476.pdf'}\n",
      "Attmpet 1\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:006e7a88-d56d-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/2340cd88df33ff3c70188c3cbd2a9476.pdf'}\n",
      "Attmpet 2\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:91fdc04e-d56d-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/2340cd88df33ff3c70188c3cbd2a9476.pdf'}\n",
      "Attmpet 3\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:257698b4-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/2340cd88df33ff3c70188c3cbd2a9476.pdf'}\n",
      "Attmpet 4\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:b4c5ec4a-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/e749b9e8ea2f0fe4b2893f5cd555776a.pdf'}\n",
      "Attmpet 0\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:bcaa2ed0-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/e749b9e8ea2f0fe4b2893f5cd555776a.pdf'}\n",
      "Attmpet 1\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:c5c8e484-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/e749b9e8ea2f0fe4b2893f5cd555776a.pdf'}\n",
      "Attmpet 2\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:d01167a4-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/e749b9e8ea2f0fe4b2893f5cd555776a.pdf'}\n",
      "Attmpet 3\n",
      "File uploaded successfully!\n",
      "{'id': 'saq:job:swparse:d8a280ec-d56e-11ef-9804-0242ac120009', 'status': 'PENDING', 's3_url': 'swparse/e749b9e8ea2f0fe4b2893f5cd555776a.pdf'}\n",
      "Attmpet 4\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "files = [\n",
    "    # 'My-Agreements-in-4i-Tip-Sheet_508-1.pdf',\n",
    "    # '2024 Sales Presentation C6501-PPOs-1.pdf',\n",
    "    'CMS_AI_Playbook_3_Final.pdf',\n",
    "]\n",
    "\n",
    "output_data:list[dict[str, Any]] = []\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for filename in files:\n",
    "    results:dict[str, Any] = {\"file_name\": filename}\n",
    "    \n",
    "    content = get_file_content(filename)\n",
    "   \n",
    "    file = {\n",
    "            'file': (filename, content, 'application/pdf')\n",
    "    }\n",
    "\n",
    "    # Markdown Extraction\n",
    "    markdown_times = process_file(file, \"markdown\", force_ocr=False, plain_text=False)\n",
    "    results[\"markdown\"] = markdown_times\n",
    "    \n",
    "    # Force OCR\n",
    "    force_ocr_times = process_file(file, \"markdown\", force_ocr=True, plain_text=False)\n",
    "    results[\"force_ocr\"] = force_ocr_times\n",
    "    \n",
    "    # Plain Text\n",
    "    plain_text_times = process_file(file, \"text\", force_ocr=False, plain_text=True)\n",
    "    results[\"plain_text\"] = plain_text_times\n",
    "    \n",
    " \n",
    "    output_data.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"time_taken(async).md\", \"w\") as f:\n",
    "    for data in output_data:\n",
    "        \n",
    "        markdown_times = data.get(\"markdown\", [])\n",
    "        force_ocr_times = data.get(\"force_ocr\", [])\n",
    "        plain_text_times = data.get(\"plain_text\", [])\n",
    " \n",
    "        max_attempts = max(len(markdown_times), len(force_ocr_times), len(plain_text_times))\n",
    "\n",
    "        \n",
    "        f.write(f\"`File name`:  {data['file_name']}\\n\\n\")\n",
    "        f.write(\"| Metric         | Markdown Extraction   |     Force OCR       |    Plain Text       |\\n\")\n",
    "        f.write(\"|----------------|-----------------------|---------------------|---------------------|\\n\")\n",
    "        \n",
    "        for i in range(max_attempts):\n",
    "            md_time = data[\"markdown\"][i]\n",
    "            ocr_time = data[\"force_ocr\"][i]\n",
    "            pt_time = data[\"plain_text\"][i]\n",
    "            \n",
    "            md_time_str = get_time_str(md_time)\n",
    "            ocr_time_str = get_time_str(ocr_time)\n",
    "            pt_time_str = get_time_str(pt_time)\n",
    "            \n",
    "            f.write(f\"| {i+1}st Attempt | {md_time_str} | {ocr_time_str} | {pt_time_str} |\\n\")\n",
    "        \n",
    "        avg_md = get_average_str(data[\"markdown\"])\n",
    "        avg_ocr = get_average_str(data[\"force_ocr\"])\n",
    "        avg_pt = get_average_str(data[\"plain_text\"])\n",
    "        \n",
    "        f.write(\"|                |                       |                     |                     |\\n\")\n",
    "        f.write(f\"|    Avg Time    | {avg_md} | {avg_ocr} | {avg_pt} |\\n\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testing: markdown extraction with markitdown\"\"\"\n",
    "\n",
    "from markitdown import MarkItDown\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    " \n",
    "files = [\n",
    "    'My-Agreements-in-4i-Tip-Sheet_508-1.pdf',\n",
    "    '2024 Sales Presentation C6501-PPOs-1.pdf',\n",
    "    'CMS_AI_Playbook_3_Final.pdf',\n",
    "]\n",
    " \n",
    "FOLDER = \"output(markitdown)\"\n",
    " \n",
    "Path(FOLDER).mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "table_data = []\n",
    " \n",
    "for filename in files:\n",
    "    filepath = f\"pdf/{filename}\"\n",
    "    \n",
    "    start_time = datetime.now()\n",
    " \n",
    "    md = MarkItDown()\n",
    "    result = md.convert(filepath)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    time_taken = end_time - start_time\n",
    " \n",
    "    md_filename = filename.replace(\".pdf\", \".md\")\n",
    "    write_file(f\"{FOLDER}/{md_filename}\", result.text_content)\n",
    " \n",
    "    table_data.append((filename, time_taken))\n",
    "\n",
    " \n",
    "markdown_table = \"| File Name                                    | Time Taken          |\\n\"\n",
    "markdown_table += \"|----------------------------------------------|---------------------|\\n\"\n",
    "\n",
    "for file, time_taken in table_data:\n",
    "    markdown_table += f\"| {file} | {get_time_str(time_taken)} |\\n\"\n",
    "\n",
    " \n",
    "print(markdown_table)\n",
    "\n",
    "write_file(f\"{FOLDER}/time_taken_summary.md\", markdown_table) \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testing: markdown extraction with docling\"\"\"\n",
    "\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import torch\n",
    "  \n",
    "print(torch.cuda.is_available())   \n",
    " \n",
    "\n",
    "def write_file(filename: str, content: str):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    " \n",
    "files = [\n",
    "    'My-Agreements-in-4i-Tip-Sheet_508-1.pdf',\n",
    "    '2024 Sales Presentation C6501-PPOs-1.pdf',\n",
    "    'CMS_AI_Playbook_3_Final.pdf',\n",
    "]\n",
    "attempt = 5\n",
    "\n",
    "FOLDER = \"output(docling)\"\n",
    "Path(FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for filename in files:\n",
    "    filepath = f\"pdf/{filename}\"\n",
    "    \n",
    "    time_taken_list = []\n",
    "    for _ in range(attempt):   \n",
    "        start_time = datetime.now()\n",
    "\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(filepath)\n",
    "        markdown_content = result.document.export_to_markdown()\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        time_taken = end_time - start_time\n",
    "        time_taken_list.append(time_taken)\n",
    "\n",
    "        md_filename = filename.replace(\".pdf\", \".md\")\n",
    "        write_file(f\"{FOLDER}/{md_filename}\", markdown_content)\n",
    " \n",
    "    avg_time_taken = sum(time_taken_list, timedelta()) / len(time_taken_list)\n",
    "    table_data.append((filename, time_taken_list, avg_time_taken))\n",
    "\n",
    " \n",
    "markdown_table = \"| File Name                                    | Time Taken (1st) | Time Taken (2nd) | Time Taken (3rd) | Time Taken (4th) | Time Taken (5th) | Average Time Taken |\\n\"\n",
    "markdown_table += \"|----------------------------------------------|------------------|------------------|------------------|------------------|------------------|--------------------|\\n\"\n",
    "\n",
    "for file, time_taken_list, avg_time_taken in table_data:\n",
    "    time_taken_str = \" | \".join([get_time_str(time) for time in time_taken_list])\n",
    "    markdown_table += f\"| {file} | {time_taken_str} | {get_time_str(avg_time_taken)} |\\n\"\n",
    "\n",
    "print(markdown_table)\n",
    "\n",
    "write_file(f\"{FOLDER}/time_taken_summary.md\", markdown_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
